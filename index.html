<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Primary Meta Tags -->
  <meta name="title" content="Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts (HEX) - Lee, Moon, Zhai, Chithanar, Sahu, Kar, Lee, Chakraborty, Bedi">
  <meta name="description" content="HEX is a training-free inference method for diffusion LLMs that ensembles semi-autoregressive schedules and majority-votes outputs, yielding large gains on GSM8K, MATH, ARC-C, and TruthfulQA.">
  <meta name="keywords" content="diffusion LLMs, semi-autoregressive, test-time scaling, HEX, reasoning, GSM8K, MATH, ARC-C, TruthfulQA, ensemble">
  <meta name="author" content="Jihoon Lee, Hoyeon Moon, Kevin Zhai, Arun Kumar Chithanar, Anit Kumar Sahu, Soummya Kar, Chul Lee, Souradip Chakraborty, Amrit Singh Bedi">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="HEX: Hidden Semi-Autoregressive Experts">
  <meta property="og:title" content="Test-Time Scaling in Diffusion LLMs via HEX">
  <meta property="og:description" content="Training-free semi-AR ensembling for diffusion LLMs; majority-vote across schedules for robust accuracy gains.">
  <meta property="og:url" content="https://junos-ai-org.github.io/Test-Time-Scaling/">
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="HEX â€” Test-Time Scaling in dLLMs">
  <meta property="article:published_time" content="2025-01-01T00:00:00.000Z">
  <meta property="article:author" content="Jihoon Lee">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="diffusion LLMs">
  <meta property="article:tag" content="semi-autoregressive">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <meta name="twitter:creator" content="@YOUR_TWITTER_HANDLE">
  <meta name="twitter:title" content="Test-Time Scaling in Diffusion LLMs via HEX">
  <meta name="twitter:description" content="Training-free ensembling over semi-AR schedules for robust accuracy improvements at inference time.">
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="HEX â€” Test-Time Scaling in dLLMs">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts">
  <meta name="citation_author" content="Lee, Jihoon">
  <meta name="citation_author" content="Moon, Hoyeon">
  <meta name="citation_author" content="Zhai, Kevin">
  <meta name="citation_author" content="Chithanar, Arun Kumar">
  <meta name="citation_author" content="Sahu, Anit Kumar">
  <meta name="citation_author" content="Kar, Soummya">
  <meta name="citation_author" content="Lee, Chul">
  <meta name="citation_author" content="Chakraborty, Souradip">
  <meta name="citation_author" content="Bedi, Amrit Singh">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="Preprint">
  <meta name="citation_pdf_url" content="https://junos-ai-org.github.io/Test-Time-Scaling/">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>HEX â€” Test-Time Scaling in Diffusion LLMs | Academic Research</title>

  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">

  <!-- Critical CSS -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- Optional (ì•ˆ ì¨ë„ ë¨) -->
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="static/css/fontawesome.all.min.css"></noscript>

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <!-- JS -->
  <script defer src="static/js/fontawesome.all.min.js"></script>

  <!-- ğŸŸ¢ Background control -->
  <style>
    /* ê¸°ë³¸: ëª¨ë“  section/heroëŠ” ì˜…ì€ íšŒìƒ‰ */
    section.section,
    section.hero {
      background-color: #f5f5f5;
    }

    /* Bulmaì˜ is-lightë¥¼ ë®ì–´ì¨ì„œ í†¤ í†µì¼ */
    section.hero.is-light {
      background-color: #f5f5f5 !important;
    }

    /* ì„¹ì…˜ ë‚´ë¶€ì— ì´ë¯¸ì§€ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ í° ë°°ê²½ */
    section.section:has(img),
    section.hero:has(img) {
      background-color: #ffffff !important;
    }

    /* Footerë„ ì‚¬ì´íŠ¸ í†¤ì— ë§ì¶° ì˜…ì€ íšŒìƒ‰ */
    footer.footer {
      background-color: #f5f5f5;
    }

    /* ë¶€ë“œëŸ¬ìš´ ì „í™˜ (ì„ íƒ) */
    section {
      transition: background-color 0.25s ease-in-out;
    }

    /* :has() ë¯¸ì§€ì› ë¸Œë¼ìš°ì € í´ë°±ìš© í´ë˜ìŠ¤ */
    section.has-image {
      background-color: #ffffff !important;
    }
  </style>

  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context":"https://schema.org",
    "@type":"ScholarlyArticle",
    "headline":"Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts (HEX)",
    "description":"HEX ensembles semi-autoregressive schedules and majority-votes outputs, achieving strong gains on reasoning benchmarks without retraining.",
    "author":[
      {"@type":"Person","name":"Jihoon Lee","affiliation":{"@type":"Organization","name":"Yonsei University"}},
      {"@type":"Person","name":"Hoyeon Moon","affiliation":{"@type":"Organization","name":"Yonsei University"}},
      {"@type":"Person","name":"Kevin Zhai","affiliation":{"@type":"Organization","name":"University of Central Florida"}},
      {"@type":"Person","name":"Arun Kumar Chithanar"},
      {"@type":"Person","name":"Anit Kumar Sahu","affiliation":{"@type":"Organization","name":"Oracle"}},
      {"@type":"Person","name":"Soummya Kar","affiliation":{"@type":"Organization","name":"Carnegie Mellon University"}},
      {"@type":"Person","name":"Chul Lee"},
      {"@type":"Person","name":"Souradip Chakraborty","affiliation":{"@type":"Organization","name":"University of Maryland, College Park"}},
      {"@type":"Person","name":"Amrit Singh Bedi","affiliation":{"@type":"Organization","name":"University of Central Florida"}}
    ],
    "datePublished":"2025-01-01",
    "publisher":{"@type":"Organization","name":"Preprint"},
    "url":"https://junos-ai-org.github.io/Test-Time-Scaling/",
    "image":"https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords":["diffusion LLMs","semi-autoregressive","HEX","reasoning","ensemble","GSM8K","MATH","ARC-C","TruthfulQA"],
    "abstract":"Diffusion-based large language models (dLLMs) are trained flexibly to model extreme dependence in the data distribution; however, how to best utilize this information at inference time remains an open problem. In this work, we uncover an interesting property of these models: dLLMs trained on textual data implicitly learn a mixture of semi-autoregressive experts, where different generation orders reveal different specialized behaviors. We show that committing to any single, fixed inference time schedule, a common practice, collapses performance by failing to leverage this latent ensemble. To address this, we introduce HEX (Hidden semiautoregressive EXperts for test-time scaling), a training-free inference method that ensembles across heterogeneous block schedules. By doing a majority vote over diverse block-sized generation paths, HEX robustly avoids failure modes associated with any single fixed schedule. On reasoning benchmarks such as GSM8K, it boosts accuracy by up to 3.56Ã— (from 24.72% to 88.10%), outperforming top-K margin inference and specialized fine-tuned methods like GRPO, without additional training. HEX even yields significant gains on MATH benchmark from 16.40% to 40.00%, scientific reasoning on ARC-C from 54.18% to 87.80%, and TruthfulQA from 28.36% to 57.46%. Our results establish a new paradigm for test-time scaling in diffusion-based LLMs (dLLMs), revealing that the sequence in which masking is performed plays a critical role in determining performance during inference.",
    "isAccessibleForFree":true,
    "license":"https://creativecommons.org/licenses/by/4.0/",
    "mainEntity":{"@type":"WebPage","@id":"https://junos-ai-org.github.io/Test-Time-Scaling/"}
  }
  </script>

  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context":"https://schema.org",
    "@type":"Organization",
    "name":"HEX Project",
    "url":"https://junos-ai-org.github.io/Test-Time-Scaling/",
    "logo":"https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs":["https://github.com/junos-ai-org/hex"]
  }
  </script>
</head>
<body>

  <!-- Scroll to Top Button (ì˜µì…˜) -->
  <button class="scroll-to-top" onclick="window.scrollTo({top:0,behavior:'smooth'})" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- (ì˜µì…˜) More Works Dropdown â€” ì›í•˜ë©´ ìœ ì§€/ì‚­ì œ -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="document.getElementById('moreWorksDropdown').classList.toggle('is-active')" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="document.getElementById('moreWorksDropdown').classList.remove('is-active')">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- í•„ìš”ì‹œ ì±„ìš°ê¸° -->
      </div>
    </div>
  </div>

  <main id="main-content">
    <!-- ìƒë‹¨ Hero / ì €ì ì˜ì—­ -->
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts (HEX)
              </h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block"><a href="#" target="_blank">Jihoon Lee</a><sup>1</sup>,</span>
                <span class="author-block"><a href="#" target="_blank">Hoyeon Moon</a><sup>1</sup>,</span>
                <span class="author-block"><a href="#" target="_blank">Kevin Zhai</a><sup>5</sup>,</span>
                <span class="author-block"><a href="#" target="_blank">Arun Kumar Chithanar</a>,</span>
                <span class="author-block"><a href="#" target="_blank">Anit Kumar Sahu</a><sup>2</sup>,</span>
                <span class="author-block"><a href="#" target="_blank">Soummya Kar</a><sup>3</sup>,</span>
                <span class="author-block"><a href="#" target="_blank">Chul Lee</a>,</span>
                <span class="author-block"><a href="#" target="_blank">Souradip Chakraborty</a><sup>4</sup>,</span>
                <span class="author-block"><a href="#" target="_blank">Amrit Singh Bedi</a><sup>5</sup></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <sup>1</sup><a href="https://www.yonsei.ac.kr/" target="_blank">Yonsei University</a> &nbsp;
                  <sup>2</sup><a href="https://www.oracle.com/" target="_blank">Oracle</a> &nbsp;
                  <sup>3</sup><a href="https://www.cmu.edu/" target="_blank">Carnegie Mellon University</a> &nbsp;
                  <sup>4</sup><a href="https://www.umd.edu/" target="_blank">University of Maryland, College Park</a> &nbsp;
                  <sup>5</sup><a href="https://www.ucf.edu/" target="_blank">University of Central Florida</a>
                  <br>Preprint 2025
                </span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links" style="margin-top:.75rem;">
                  <span class="link-block">
                    <a href="https://junos-ai-org.github.io/Test-Time-Scaling/" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon"><i class="fas fa-file"></i></span>
                      <span>Paper / Project Page</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://github.com/junos-ai-org/hex" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon"><i class="fab fa-github"></i></span>
                      <span>Code</span>
                    </a>
                  </span>
                </div>
              </div>

            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- í‹°ì € GIF (ì´ë¯¸ì§€ â†’ í° ë°°ê²½) -->
    <section class="section">
      <div class="container is-max-desktop">
        <figure class="image" style="margin:0 auto; max-width: 1000px;">
          <img src="assets/HEX_visualization_sample_2.gif" alt="HEX visualization sample" loading="lazy" style="width:100%; height:auto;">
        </figure>
      </div>
    </section>

    <!-- Abstract (ì´ë¯¸ì§€ í¬í•¨ â†’ í° ë°°ê²½) -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-10">
            <h2 class="title is-3 has-text-centered">Abstract</h2>

            <div class="columns is-variable is-5 is-vcentered">
              <div class="column is-6">
                <figure class="image" style="margin: 0 auto;">
                  <img src="assets/HEX.png" alt="Left figure" loading="lazy">
                  <figcaption class="has-text-grey has-text-centered" style="margin-top:.5rem;">
                    Left: <code> </code>
                  </figcaption>
                </figure>
              </div>

              <div class="column is-6">
                <figure class="image" style="margin: 0 auto;">
                  <img src="assets/figure_avg.png" alt="Right figure" loading="lazy">
                  <figcaption class="has-text-grey has-text-centered" style="margin-top:.5rem;">
                    Right: <code> </code>
                  </figcaption>
                </figure>
              </div>
            </div>

            <div class="content has-text-justified" style="margin-top: 1rem;">
              <p>
                Diffusion-based large language models (dLLMs) are trained flexibly to model extreme dependence in the data distribution; however, how to best utilize this information at
inference time remains an open problem. In this work, we uncover an interesting
property of these models: dLLMs trained on textual data implicitly learn a
mixture of semi-autoregressive experts, where different generation orders reveal
different specialized behaviors. We show that committing to any single, fixed inference
time schedule, a common practice, collapses performance by failing to
leverage this latent ensemble. To address this, we introduce <b>HEX</b> (Hidden semiautoregressive
EXperts for test-time scaling), a training-free inference method that
ensembles across heterogeneous block schedules. By doing a majority vote over
diverse block-sized generation paths, HEX robustly avoids failure modes associated
with any single fixed schedule. On reasoning benchmarks such as GSM8K,
it boosts accuracy by up to 3.56Ã— (from 24.72% to 88.10%), outperforming top-K
margin inference and specialized fine-tuned methods like GRPO, without additional
training. HEX even yields significant gains on MATH benchmark from
16.40% to 40.00%, scientific reasoning on ARC-C from 54.18% to 87.80%, and
TruthfulQA from 28.36% to 57.46%. Our results establish a new paradigm for test-time scaling in diffusion-based LLMs (dLLMs), revealing that the sequence in which masking is performed plays a critical role in determining performance during inference. 
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Key Contributions (í…ìŠ¤íŠ¸ ì¤‘ì‹¬ â†’ ì˜…ì€ íšŒìƒ‰) -->
    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-10">
            <h2 class="title is-3 has-text-centered">Key Contributions</h2>
            <div class="content" style="margin-top: 0.75rem;">
              <ul>
                <li><b>Limitation Analysis:</b> We identify why common confidence-based schedules (e.g., top-K margin) can catastrophically fail in dLLMs on reasoning tasks (e.g., [AfterEoT] collapse), revealing sensitivity to decoding order.</li>
                <li><b>HEXâ€”Test-time Scaling via Hidden Experts:</b> We uncover and exploit a <em>latent mixture</em> of semi-AR experts by marginalizing over block schedules and aggregating via majority voteâ€”introducing a new compute-accuracy knob at inference time.</li>
                <li><b>State-of-the-Art, Training-Free:</b> HEX achieves up to <strong>3.56Ã—</strong> gains and surpasses GRPO on GSM8K (88.10%), MATH (40.00%), ARC-C (87.80%), and improves TruthfulQA (57.46%)â€”all without retraining.</li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Findings (ì´ë¯¸ì§€ í¬í•¨ â†’ í° ë°°ê²½) -->
    <section class="section">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Findings</h2>

        <div class="columns is-centered">
          <div class="column is-8">
            <figure class="image">
              <img src="assets/combined_horizontal_GSM8K_149_250916.png" alt="img1" loading="lazy" style="object-fit:contain;">
              <figcaption class="has-text-grey has-text-centered" style="margin-top:.5rem;">
                Limitation Analysis: We identify why common confidence-based schedules (e.g., top-K margin) can catastrophically fail in dLLMs on reasoning tasks (e.g., [AfterEoT] collapse), revealing sensitivity to decoding order.
              </figcaption>
            </figure>
          </div>
        </div>

        <div class="columns is-centered is-variable is-5">
          <div class="column is-6-tablet is-5-desktop">
            <figure class="image">
              <img src="assets/general_crucial_distributions_overlap2.png" alt="img2" loading="lazy" style="object-fit:contain;">
            </figure>
          </div>

          <div class="column is-6-tablet is-5-desktop">
            <figure class="image">
              <img src="assets/crucial_distributions_overlap.png" alt="img3" loading="lazy" style="object-fit:contain;">
            </figure>
          </div>
        </div>

        <div class="has-text-grey has-text-centered" style="margin-top:.5rem;">
          Uncovered interesting property: dLLMs trained on textual data implicitly learn a mixture of semi-autoregressive experts, where different generation orders reveal different specialized behaviors. We show that committing to any single, fixed inference time schedule, a common practice, collapses performance by failing to leverage this latent ensemble. HEX address this, by ensembling heterogeneous block schedules. 
        </div>

      </div>
    </section>

    <!-- Result (ì´ë¯¸ì§€ í¬í•¨ â†’ í° ë°°ê²½) -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-10">
            <h2 class="title is-3 has-text-centered">Result</h2>

            <figure class="image" style="margin: 1rem auto; max-width: 1000px;">
              <img src="assets/figure_1.png" alt="Main results" loading="lazy">
              <figcaption class="has-text-grey has-text-centered" style="margin-top:.5rem;">
                State-of-the-Art, Training-Free:</span> HEX achieves up to <strong>3.56Ã—</strong> gains and surpasses GRPO on GSM8K (88.10%), MATH (40.00%), ARC-C (87.80%), and improves TruthfulQA (57.46%)â€”all without retraining. 
              </figcaption>
            </figure>
            
            <figure class="image" style="margin: 1rem auto; max-width: 1000px;">
              <img src="assets/scaling_law.png" alt="scaling" loading="lazy">
              <figcaption class="has-text-grey has-text-centered" style="margin-top:.5rem;">
                Test-Time Scaling:</span> HEXâ€™s accuracy improves monotonically as the number of voting samples increases, while the tie rate, an indicator of ambiguity, steadily declines. HEX effectively exposes a tunable accuracy, compute knob: practitioners can trade inference cost for accuracy in a predictable way, without retraining.
              </figcaption>
            </figure>

          </div>
        </div>
      </div>
    </section>

    <!-- BibTeX (í…ìŠ¤íŠ¸ ì¤‘ì‹¬ â†’ ì˜…ì€ íšŒìƒ‰) -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header" style="display:flex;align-items:center;justify-content:space-between;">
          <h2 class="title">BibTeX</h2>
          <button class="button is-small is-dark" onclick="copyBibTeX()" title="Copy BibTeX">
            <span class="icon"><i class="fas fa-copy"></i></span><span>Copy</span>
          </button>
        </div>
<pre id="bibtex-code"><code>@article{lee2025hex,
  title   = {Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts},
  author  = {Jihoon Lee and Hoyeon Moon and Kevin Zhai and Arun Kumar Chithanar and
             Anit Kumar Sahu and Soummya Kar and Chul Lee and Souradip Chakraborty and
             Amrit Singh Bedi},
  journal = {arXiv preprint},
  year    = {2025},
  note    = {Project page: https://junos-ai-org.github.io/Test-Time-Scaling/}
}</code></pre>
      </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This page was built using the
                <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> (CC BY-SA 4.0).
                Content adapted from the HEX project.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </main>

  <!-- Helpers -->
  <script>
    function copyBibTeX() {
      const el = document.getElementById('bibtex-code');
      if (!el) return;
      const text = el.innerText || el.textContent;
      navigator.clipboard.writeText(text).then(() => alert('BibTeX copied!'));
    }

    // :has() ë¯¸ì§€ì› ë¸Œë¼ìš°ì € í´ë°±: ì´ë¯¸ì§€ê°€ ìˆëŠ” ì„¹ì…˜ì— .has-image í´ë˜ìŠ¤ ë¶€ì—¬
    (function () {
      try {
        // ì¼ë¶€ ë¸Œë¼ìš°ì €ì—ì„œëŠ” querySelector(':has') í˜¸ì¶œì—ì„œ ì—ëŸ¬ê°€ ë‚˜ë¯€ë¡œ try-catch
        document.querySelector('section:has(img)');
        // ì§€ì›í•˜ë©´ ì•„ë¬´ ê²ƒë„ í•˜ì§€ ì•ŠìŒ (CSSê°€ ì²˜ë¦¬)
      } catch (e) {
        document.querySelectorAll('section').forEach(function (sec) {
          if (sec.querySelector('img')) {
            sec.classList.add('has-image');
          }
        });
      }
    })();
  </script>
</body>
</html>
